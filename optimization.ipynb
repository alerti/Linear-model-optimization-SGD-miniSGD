{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week01_pa.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iku8nFSUMJxX",
        "colab_type": "text"
      },
      "source": [
        "#Linear models, Optimization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meCI0iMLMJxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf0Tr3MEMJxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjNINAzmMJxn",
        "colab_type": "text"
      },
      "source": [
        "## Two-dimensional classification\n",
        "\n",
        "solve 2D classification with synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IW_qJ0bMJxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('~/*link to file*/train.npy', 'rb') as fin:\n",
        "    X = np.load(fin)\n",
        "    \n",
        "with open('!/*link to file*/target.npy', 'rb') as fin:\n",
        "    y = np.load(fin)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, s=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OZefUUJMJxv",
        "colab_type": "text"
      },
      "source": [
        "## Features\n",
        "\n",
        "\n",
        "Note the data is non-separable so w gonna add features and use non-linear model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kqs_WDcMJxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def expand(X):\n",
        "    \"\"\"\n",
        "    Adds quadratic features. \n",
        "    This expansion allows your linear model to make non-linear separation.\n",
        "    \"\"\"\n",
        "    X_expanded = np.zeros((X.shape[0], 6))\n",
        "    X_expanded[:, 0] = X[:, 0]\n",
        "    X_expanded[:, 1] = X[:, 1]\n",
        "    X_expanded[:, 2] = X[:, 0] ** 2\n",
        "    X_expanded[:, 3] = X[:, 1] ** 2\n",
        "    X_expanded[:, 4] = X[:, 0] * X[:, 1] \n",
        "    X_expanded[:, 5] = 1\n",
        "    return X_expanded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt_qD-dhMJx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_expanded = expand(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrkOsR4MJx8",
        "colab_type": "text"
      },
      "source": [
        "lets test for your implementation of `expand` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwl8im6XMJx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test on random numbers\n",
        "\n",
        "dummy_X = np.array([\n",
        "        [0,0],\n",
        "        [1,0],\n",
        "        [2.61,-1.28],\n",
        "        [-0.59,2.1]\n",
        "    ])\n",
        "\n",
        "# call your expand function\n",
        "dummy_expanded = expand(dummy_X)\n",
        "\n",
        "# what it should have returned:   x0       x1       x0^2     x1^2     x0*x1    1\n",
        "dummy_expanded_ans = np.array([[ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  1.    ],\n",
        "                               [ 1.    ,  0.    ,  1.    ,  0.    ,  0.    ,  1.    ],\n",
        "                               [ 2.61  , -1.28  ,  6.8121,  1.6384, -3.3408,  1.    ],\n",
        "                               [-0.59  ,  2.1   ,  0.3481,  4.41  , -1.239 ,  1.    ]])\n",
        "\n",
        "#tests\n",
        "assert isinstance(dummy_expanded,np.ndarray), \"should return numpy array\"\n",
        "assert dummy_expanded.shape == dummy_expanded_ans.shape, \"brings correct shape\"\n",
        "assert np.allclose(dummy_expanded,dummy_expanded_ans,1e-3),\n",
        "\n",
        "print(\"Seems legit!\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1REyM14MJyG",
        "colab_type": "text"
      },
      "source": [
        "## Logistic regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iY6oKqrMJyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def probability(X, w):\n",
        "   \n",
        "    \n",
        "    return 1 / (1 + np.exp(-np.dot(X, w)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4DP0wmtMJyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy_weights = np.linspace(-1, 1, 6)\n",
        "kanda = probability(X_expanded[:1, :], dummy_weights)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMCoyzajMJyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVtySir-MJya",
        "colab_type": "text"
      },
      "source": [
        "cross-entropy minimization:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBbtEXp2MJyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(X, y, w):\n",
        "  \n",
        "    \n",
        "    p = probability(X, w)\n",
        "    return -np.mean(y * np.log(p) + (1 - y) * np.log(1 - p))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmQ9YJV6MJye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kanda2 = compute_loss(X_expanded, y, dummy_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Iinr3ZDMJyt",
        "colab_type": "text"
      },
      "source": [
        "compute gradients, to train model with gradient descent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atT4KFwEMJyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_grad(X, y, w):\n",
        "\n",
        "    return np.dot(X.T, probability(X, w) - y) / X.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jhRsGz9MJy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use output of this cell to fill answer field \n",
        "kanda3 = np.linalg.norm(compute_grad(X_expanded, y, dummy_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK5WDZKDMJzN",
        "colab_type": "text"
      },
      "source": [
        " visualize the predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EKi2mSAMJzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython import display\n",
        "\n",
        "h = 0.01\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "def visualize(X, y, w, history):\n",
        "    \"\"\"draws classifier prediction with matplotlib magic\"\"\"\n",
        "    Z = probability(expand(np.c_[xx.ravel(), yy.ravel()]), w)\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history)\n",
        "    plt.grid()\n",
        "    ymin, ymax = plt.ylim()\n",
        "    plt.ylim(0, ymax)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR6u2ifbMJzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize(X, y, dummy_weights, [0.5, 0.5, 0.25])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci84RcE8MJza",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "using stochastic gradient descent.\n",
        "\n",
        "try to change hyperparameters like batch size,\n",
        "learning rate to find best one,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcQoipxMMJzb",
        "colab_type": "text"
      },
      "source": [
        "## Mini-batch SGD\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpx2-VgUMJzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# please use np.random.seed(42), eta=0.1, n_iter=100 and batch_size=4 for deterministic results\n",
        "\n",
        "np.random.seed(42)\n",
        "w = np.array([0, 0, 0, 0, 0, 1])\n",
        "\n",
        "eta= 0.1 # learning rate\n",
        "\n",
        "n_iter = 100\n",
        "batch_size = 4\n",
        "loss = np.zeros(n_iter)\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "for i in range(n_iter):\n",
        "    ind = np.random.choice(X_expanded.shape[0], batch_size)\n",
        "    loss[i] = compute_loss(X_expanded, y, w)\n",
        "    if i % 10 == 0:\n",
        "        visualize(X_expanded[ind, :], y[ind], w, loss)\n",
        " \n",
        "    w = w - eta * compute_grad(X_expanded[ind, :], y[ind], w)\n",
        "\n",
        "visualize(X, y, w, loss)\n",
        "plt.clf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfLt0YOgMJze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "alerti = compute_loss(X_expanded, y, w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmCGKICoMJzt",
        "colab_type": "text"
      },
      "source": [
        "## SGD with momentum\n",
        "\n",
        "Momentum is a method that helps accelerate SGD in the relevant direction and dampens oscillations as can be seen in image below. It does this by adding a fraction $\\alpha$ of the update vector of the past time step to the current update vector.\n",
        "www.wikipedia.com\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAF_euReMJzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deterministic results\n",
        "np.random.seed(42)\n",
        "w = np.array([0, 0, 0, 0, 0, 1])\n",
        "\n",
        "eta = 0.05 # learning rate\n",
        "alpha = 0.9 # momentum\n",
        "nu = np.zeros_like(w)\n",
        "\n",
        "n_iter = 100\n",
        "batch_size = 4\n",
        "loss = np.zeros(n_iter)\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "for i in range(n_iter):\n",
        "    ind = np.random.choice(X_expanded.shape[0], batch_size)\n",
        "    loss[i] = compute_loss(X_expanded, y, w)\n",
        "    if i % 10 == 0:\n",
        "        visualize(X_expanded[ind, :], y[ind], w, loss)\n",
        "\n",
        "    # TODO:<your code here>\n",
        "    nu = alpha * nu + eta * compute_grad(X_expanded[ind, :], y[ind], w)\n",
        "    w = w - nu\n",
        "\n",
        "visualize(X, y, w, loss)\n",
        "plt.clf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63tx6imaMJz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use output of this cell to fill answer field \n",
        "\n",
        "alerti1= compute_loss(X_expanded, y, w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQscNIeuMJ0B",
        "colab_type": "text"
      },
      "source": [
        "## RMSprop\n",
        "\n",
        "Implement RMSPROP algorithm, which use squared gradients to adjust learning rate:\n",
        "\n",
        "wikipedia.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhD-OBWhMJ0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "w = np.array([0, 0, 0, 0, 0, 1.])\n",
        "\n",
        "eta = 0.1 # learning rate\n",
        "alpha = 0.9 # moving average of gradient norm squared\n",
        "g2 = None # we start with None so that you can update this value correctly on the first iteration\n",
        "eps = 1e-8\n",
        "\n",
        "n_iter = 100\n",
        "batch_size = 4\n",
        "loss = np.zeros(n_iter)\n",
        "plt.figure(figsize=(12,5))\n",
        "for i in range(n_iter):\n",
        "    ind = np.random.choice(X_expanded.shape[0], batch_size)\n",
        "    loss[i] = compute_loss(X_expanded, y, w)\n",
        "    if i % 10 == 0:\n",
        "        visualize(X_expanded[ind, :], y[ind], w, loss)\n",
        "\n",
        "\n",
        "    g = compute_grad(X_expanded[ind, :], y[ind], w)\n",
        "    g2 = g ** 2\n",
        "    G = alpha * G + (1 - alpha) * g2\n",
        "    w = w - eta * g / (np.sqrt(G + eps))\n",
        "\n",
        "visualize(X, y, w, loss)\n",
        "plt.clf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS5p43iiMJ0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use output of this cell to fill answer field \n",
        "alerti_3= compute_loss(X_expanded, y, w)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}